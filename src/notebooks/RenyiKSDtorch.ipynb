{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "625d477f",
      "metadata": {
        "id": "625d477f"
      },
      "outputs": [],
      "source": [
        "#!pip -q uninstall -y diffusers transformers huggingface_hub\n",
        "#!pip -q install -U \"huggingface_hub\" \"transformers\" \"diffusers\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip -q install torchmetrics\n",
        "#!pip -q install torch-fidelity\n",
        "\n"
      ],
      "metadata": {
        "id": "58XEZzSwcagM"
      },
      "id": "58XEZzSwcagM",
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "65b97d3d",
      "metadata": {
        "id": "65b97d3d"
      },
      "outputs": [],
      "source": [
        "from diffusers import DDPMPipeline\n",
        "from torchvision import datasets, transforms\n",
        "import random, numpy as np, torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "\n",
        "seed = 123\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "4adb6d6a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "e51531bd78504d71a828896cb2ecc37f",
            "a78b7b0829d9446f900293b91e19e2df",
            "2a731cb70e0549f5a50d9e4c1734e43f",
            "7143a53510ac49b593e527347fcec615",
            "7ed2849475ea48108300e7fd45ed35c7",
            "753f0ad277f74608881370fcb0c1c2b7",
            "2874d5bcd06f4c9a9b3b3e4de2788697",
            "3ce3aa6d78924c8ca8b3084868d0b6c2",
            "ef03039327a146559748ab045a4fa4a9",
            "f58a213a1bd94d53b97d214cccdd2473",
            "b0d5fc358e564bc4a212c7fe7f49efd7"
          ]
        },
        "id": "4adb6d6a",
        "outputId": "e60ab83a-57ad-4d80-c928-331f4ebd80c1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading pipeline components...:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e51531bd78504d71a828896cb2ecc37f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "An error occurred while trying to fetch /root/.cache/huggingface/hub/models--google--ddpm-cifar10-32/snapshots/267b167dc01f0e4e61923ea244e8b988f84deb80: Error no file named diffusion_pytorch_model.safetensors found in directory /root/.cache/huggingface/hub/models--google--ddpm-cifar10-32/snapshots/267b167dc01f0e4e61923ea244e8b988f84deb80.\n",
            "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n"
          ]
        }
      ],
      "source": [
        "# ----------------------------\n",
        "# Load pretrained DDPM (CIFAR10)\n",
        "# ----------------------------\n",
        "pipe = DDPMPipeline.from_pretrained(\"google/ddpm-cifar10-32\").to(device)\n",
        "pipe.set_progress_bar_config(disable=True)\n",
        "unet = pipe.unet.eval()\n",
        "\n",
        "for p in unet.parameters():\n",
        "    p.requires_grad_(False)\n",
        "\n",
        "alphas_cumprod = pipe.scheduler.alphas_cumprod.to(device)  # shape [T]\n",
        "T = alphas_cumprod.shape[0]\n",
        "\n",
        "# DDPM marginal: x_t = sqrt(a_bar_t) x0 + sqrt(1-a_bar_t) eps\n",
        "def add_ddpm_noise(x0, t, eps=None):\n",
        "    \"\"\"\n",
        "    x0: (B,3,32,32) in [-1,1]\n",
        "    t:  int timestep in [0, T-1]\n",
        "    \"\"\"\n",
        "    if eps is None:\n",
        "        eps = torch.randn_like(x0)\n",
        "    a_bar = alphas_cumprod[t]\n",
        "    mean_coeff = torch.sqrt(a_bar)\n",
        "    sigma_t = torch.sqrt(1.0 - a_bar)   # <-- DDPM noise std\n",
        "    x_t = mean_coeff * x0 + sigma_t * eps\n",
        "    return x_t, sigma_t\n",
        "\n",
        "def score_fn_xt(x_t, t, sigma_t=None, with_grad=False):\n",
        "    \"\"\"\n",
        "    Returns score wrt x_t: ∇_{x_t} log p_t(x_t) ≈ - eps_pred / sigma_t\n",
        "    If with_grad=True, allows gradients wrt x_t (unet weights stay frozen).\n",
        "    \"\"\"\n",
        "    if sigma_t is None:\n",
        "        sigma_t = torch.sqrt(1.0 - alphas_cumprod[t])\n",
        "\n",
        "    t_tensor = torch.full((x_t.shape[0],), int(t), device=x_t.device, dtype=torch.long)\n",
        "\n",
        "    if with_grad:\n",
        "        eps_pred = unet(x_t, t_tensor).sample   # grad flows to x_t\n",
        "    else:\n",
        "        with torch.no_grad():\n",
        "            eps_pred = unet(x_t, t_tensor).sample\n",
        "\n",
        "    return -(eps_pred / sigma_t)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "5c2ef5ff",
      "metadata": {
        "id": "5c2ef5ff"
      },
      "outputs": [],
      "source": [
        "tfm = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Lambda(lambda z: z*2-1),\n",
        "])\n",
        "cifar = datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=tfm)\n",
        "loader = torch.utils.data.DataLoader(cifar, batch_size=64, shuffle=True, num_workers=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "141cd111",
      "metadata": {
        "id": "141cd111"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def select_renyi_landmarks_torch(X, m, sigma2=0.5):\n",
        "    # X: (n,3,32,32)\n",
        "    n = X.shape[0]\n",
        "    m = min(m, n)\n",
        "    Xf = X.view(n, -1)\n",
        "\n",
        "    # squared distances (n,n)\n",
        "    dist2 = torch.cdist(Xf, Xf, p=2.0) ** 2\n",
        "    K = torch.exp(-dist2 / (2.0 * sigma2))\n",
        "    diag = torch.diagonal(K)\n",
        "\n",
        "    row_sums = K.sum(dim=1)\n",
        "    first = torch.argmin(row_sums).item()\n",
        "\n",
        "    selected = [first]\n",
        "    cross_sums = K[:, first].clone()\n",
        "\n",
        "    while len(selected) < m:\n",
        "        scores = 2 * cross_sums + diag\n",
        "        scores[selected] = float(\"inf\")\n",
        "        nxt = torch.argmin(scores).item()\n",
        "        selected.append(nxt)\n",
        "        cross_sums += K[:, nxt]\n",
        "\n",
        "    return torch.tensor(selected, device=X.device, dtype=torch.long)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "@torch.no_grad()\n",
        "def estimate_sigma2_median_heuristic(X_t, num_pairs=512, eps=1e-6):\n",
        "    \"\"\"\n",
        "    Fast median heuristic for RBF bandwidth on flattened X_t.\n",
        "    Returns sigma2 (variance) used in exp(-||x-y||^2 / (2*sigma2)).\n",
        "    \"\"\"\n",
        "    B = X_t.shape[0]\n",
        "    Xf = X_t.view(B, -1)\n",
        "\n",
        "    # sample random pairs (i,j)\n",
        "    i = torch.randint(0, B, (num_pairs,), device=X_t.device)\n",
        "    j = torch.randint(0, B, (num_pairs,), device=X_t.device)\n",
        "\n",
        "    diff = Xf[i] - Xf[j]\n",
        "    dist2 = (diff * diff).sum(dim=1)\n",
        "\n",
        "    med = torch.median(dist2)\n",
        "    sigma2 = 0.5 * med + eps  # common choice: sigma^2 = median/2\n",
        "    return float(sigma2.item())\n"
      ],
      "metadata": {
        "id": "bFkHXaAijE_k"
      },
      "id": "bFkHXaAijE_k",
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "ff41e85f",
      "metadata": {
        "id": "ff41e85f"
      },
      "outputs": [],
      "source": [
        "class RenyiNystroemKSDTorch:\n",
        "    def __init__(self, sigma2=1.0, m_fn=lambda n: int(4*np.sqrt(n)), ridge=1e-3, mc_eps=4):\n",
        "        self.sigma2 = float(sigma2)\n",
        "        self.m_fn = m_fn\n",
        "        self.ridge = float(ridge)\n",
        "        self.mc_eps = int(mc_eps)\n",
        "\n",
        "    def h_p(self, X, Y, t, sigma_t, sigma2, with_grad_score=False):\n",
        "\n",
        "        X_flat = X.view(X.shape[0], -1)\n",
        "        Y_flat = Y.view(Y.shape[0], -1)\n",
        "\n",
        "        grad_logpX = score_fn_xt(X, t, sigma_t, with_grad=with_grad_score).view(X.shape[0], -1)\n",
        "        grad_logpY = score_fn_xt(Y, t, sigma_t, with_grad=with_grad_score).view(Y.shape[0], -1)\n",
        "\n",
        "\n",
        "        diff = X_flat[:, None, :] - Y_flat[None, :, :]\n",
        "        dist2 = (diff**2).sum(dim=2)\n",
        "\n",
        "        K = torch.exp(-dist2 / (2 * sigma2))\n",
        "\n",
        "        gram_glogp = grad_logpX @ grad_logpY.T\n",
        "        gradX = -(diff / sigma2) * K[:, :, None]\n",
        "        gradY = -gradX\n",
        "\n",
        "        B = (gradX * grad_logpY[None, :, :]).sum(dim=2)\n",
        "        C = (gradY * grad_logpX[:, None, :]).sum(dim=2)\n",
        "\n",
        "        d = X_flat.shape[1]\n",
        "        gradXY_sum = (dist2 / (sigma2**2) - d / sigma2) * K\n",
        "\n",
        "        return K * gram_glogp + B + C + gradXY_sum\n",
        "\n",
        "    def _single_stat_from_xt(self, X_t, t, sigma_t, ridge, sigma2, with_grad_score=False):\n",
        "\n",
        "        n = X_t.shape[0]\n",
        "        m = min(self.m_fn(n), n)\n",
        "\n",
        "        idx = select_renyi_landmarks_torch(X_t, m, sigma2=sigma2)\n",
        "\n",
        "        H_mn = self.h_p(X_t[idx], X_t, t=t, sigma_t=sigma_t, sigma2=sigma2, with_grad_score=with_grad_score)\n",
        "        H_mm = H_mn[:, idx]\n",
        "\n",
        "        H_mm = 0.5 * (H_mm + H_mm.T)\n",
        "        I = torch.eye(m, device=X_t.device, dtype=H_mm.dtype)\n",
        "        H_mm_reg = H_mm + ridge * I\n",
        "\n",
        "        beta = H_mn @ (torch.ones(n, 1, device=X_t.device, dtype=H_mn.dtype) / n)\n",
        "\n",
        "        x = torch.linalg.solve(H_mm_reg, beta)\n",
        "        stat = (beta.T @ x).squeeze()\n",
        "        return stat\n",
        "\n",
        "    def compute_stat_from_xt(self, X_t, t, sigma_t, ridge=None, sigma2=None, with_grad_score=False):\n",
        "        if ridge is None:\n",
        "            ridge = self.ridge\n",
        "        if sigma2 is None:\n",
        "            sigma2 = self.sigma2\n",
        "        return self._single_stat_from_xt(\n",
        "            X_t, t=int(t), sigma_t=sigma_t,\n",
        "            ridge=float(ridge), sigma2=float(sigma2),\n",
        "            with_grad_score=with_grad_score\n",
        "        )\n",
        "\n",
        "\n",
        "    def compute_stat(self, X0, t, mc_samples=None, ridge=None, sigma2=None, bw_mode=\"fixed\"):\n",
        "        if mc_samples is None:\n",
        "            mc_samples = self.mc_eps\n",
        "        if ridge is None:\n",
        "            ridge = self.ridge\n",
        "\n",
        "        stats = []\n",
        "        for _ in range(int(mc_samples)):\n",
        "            X_t, sigma_t = add_ddpm_noise(X0, t)\n",
        "\n",
        "            # bandwidth selection\n",
        "            if bw_mode == \"fixed\":\n",
        "                sigma2_eff = self.sigma2 if sigma2 is None else float(sigma2)\n",
        "            elif bw_mode == \"median\":\n",
        "                sigma2_eff = estimate_sigma2_median_heuristic(X_t)\n",
        "            else:\n",
        "                raise ValueError(\"bw_mode must be 'fixed' or 'median'\")\n",
        "\n",
        "            stats.append(self._single_stat_from_xt(X_t, t=t, sigma_t=sigma_t, ridge=float(ridge), sigma2=sigma2_eff))\n",
        "\n",
        "        return torch.stack(stats).mean()\n",
        "\n",
        "ksd = RenyiNystroemKSDTorch(sigma2=1.0, ridge=1e-3, mc_eps=4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "dcf9912d",
      "metadata": {
        "id": "dcf9912d"
      },
      "outputs": [],
      "source": [
        "class DCGANGen(nn.Module):\n",
        "    def __init__(self, z_dim=128, ngf=64):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.ConvTranspose2d(z_dim, ngf*4, 4, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(ngf*4), nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(ngf*4, ngf*2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf*2), nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(ngf*2, ngf, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf), nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(ngf, 3, 4, 2, 1, bias=False),\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        return self.net(z)\n",
        "\n",
        "G = DCGANGen(z_dim=128).to(device)\n",
        "opt = torch.optim.Adam(G.parameters(), lr=2e-4, betas=(0.5, 0.999))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "f279b7b3",
      "metadata": {
        "id": "f279b7b3",
        "outputId": "d4b73f7a-bf9c-4c0a-feee-f0312b65ad02",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KSD(real @ t=599) baseline: mean=0.56, std=0.02\n"
          ]
        }
      ],
      "source": [
        "def estimate_real_baseline(t, num_batches=5, mc_samples=4, ridge=1e-3):\n",
        "    vals = []\n",
        "    it = iter(loader)\n",
        "    for _ in range(num_batches):\n",
        "        xr, _ = next(it)\n",
        "        xr = xr.to(device)\n",
        "        vals.append(ksd.compute_stat(xr, t=t, mc_samples=mc_samples, ridge=ridge).item())\n",
        "    return float(np.mean(vals)), float(np.std(vals))\n",
        "\n",
        "# Choose an initial diffusion level (not too small at first)\n",
        "# (You can later anneal it downward.)\n",
        "t_baseline = int(0.6 * (T - 1))\n",
        "real_mean, real_std = estimate_real_baseline(t_baseline, num_batches=5)\n",
        "print(f\"KSD(real @ t={t_baseline}) baseline: mean={real_mean:.2f}, std={real_std:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def rbf_kernel_flat(X, Y, sigma2):\n",
        "    Xf = X.view(X.size(0), -1)\n",
        "    Yf = Y.view(Y.size(0), -1)\n",
        "    XX = (Xf**2).sum(dim=1, keepdim=True)\n",
        "    YY = (Yf**2).sum(dim=1, keepdim=True)\n",
        "    dist2 = XX - 2*Xf @ Yf.T + YY.T\n",
        "    return torch.exp(-dist2 / (2.0 * sigma2))\n",
        "\n",
        "def mmd2_rbf(X, Y, sigma2):\n",
        "    Kxx = rbf_kernel_flat(X, X, sigma2)\n",
        "    Kyy = rbf_kernel_flat(Y, Y, sigma2)\n",
        "    Kxy = rbf_kernel_flat(X, Y, sigma2)\n",
        "    return Kxx.mean() + Kyy.mean() - 2.0 * Kxy.mean()\n",
        "\n",
        "# ----------------------------\n",
        "# Training loop: t-mixture + bandwidth tuning + REAL ANCHOR\n",
        "# ----------------------------\n",
        "steps = 2000\n",
        "batch_size = 64\n",
        "losses = []\n",
        "log_every = 50\n",
        "\n",
        "t_min = int(0.6 * (T - 1))   # start safer\n",
        "t_max = int(0.9 * (T - 1))\n",
        "\n",
        "K_T = 4\n",
        "MC_SAMPLES = 8\n",
        "RIDGE_LAM  = 1e-3\n",
        "LAMBDA_MMD = 1.0   # try 0.1, 1.0, 10.0\n",
        "\n",
        "it = iter(loader)\n",
        "\n",
        "for i in range(steps):\n",
        "    # ---- real batch ----\n",
        "    try:\n",
        "        real0, _ = next(it)\n",
        "    except StopIteration:\n",
        "        it = iter(loader)\n",
        "        real0, _ = next(it)\n",
        "    real0 = real0.to(device)\n",
        "\n",
        "    # ---- fake batch ----\n",
        "    z = torch.randn(batch_size, 128, 1, 1, device=device)\n",
        "    fake0 = G(z)\n",
        "\n",
        "    # ---- sample t's ----\n",
        "    t_list = sample_t_batch(K_T, t_min, t_max, bias_to_small=False)\n",
        "\n",
        "    loss_terms = []\n",
        "\n",
        "    for t in t_list:\n",
        "        fake_t, sigma_t = add_ddpm_noise(fake0, t)\n",
        "        real_t, _       = add_ddpm_noise(real0, t)\n",
        "\n",
        "        Xt = torch.cat([real_t, fake_t], dim=0)\n",
        "        sigma2_eff = estimate_sigma2_median_heuristic(Xt)\n",
        "\n",
        "        # KSD on x_t (NOT on x0), and allow grad wrt x_t\n",
        "        ksd_t = ksd.compute_stat_from_xt(\n",
        "            X_t=fake_t,\n",
        "            t=t,\n",
        "            sigma_t=sigma_t,\n",
        "            ridge=RIDGE_LAM,\n",
        "            sigma2=sigma2_eff,\n",
        "            with_grad_score=True,   # IMPORTANT\n",
        "        )\n",
        "\n",
        "        mmd_t = mmd2_rbf(real_t, fake_t, sigma2=sigma2_eff)\n",
        "\n",
        "        loss_terms.append(ksd_t + LAMBDA_MMD * mmd_t)\n",
        "\n",
        "\n",
        "    loss = torch.stack(loss_terms).mean()\n",
        "\n",
        "    if not torch.isfinite(loss):\n",
        "        print(f\"Skipping step {i} due to non-finite loss\")\n",
        "        continue\n",
        "\n",
        "    opt.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    torch.nn.utils.clip_grad_norm_(G.parameters(), max_norm=5.0)\n",
        "    opt.step()\n",
        "\n",
        "    losses.append(loss.item())\n",
        "\n",
        "    if (i + 1) % log_every == 0:\n",
        "        print(f\"Step {i+1}: t_list={t_list} | loss={loss.item():.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3VObKQDAjTM",
        "outputId": "fe3cd54c-ee7c-4028-b2c9-5e61e62d32d5"
      },
      "id": "t3VObKQDAjTM",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 50: t_list=[731, 686, 872, 810] | loss=24.146\n",
            "Step 100: t_list=[869, 754, 630, 617] | loss=24.433\n",
            "Step 150: t_list=[661, 842, 648, 861] | loss=24.173\n",
            "Step 200: t_list=[892, 601, 801, 696] | loss=24.267\n",
            "Step 250: t_list=[688, 886, 764, 634] | loss=24.170\n",
            "Step 300: t_list=[688, 874, 887, 658] | loss=24.046\n",
            "Step 350: t_list=[788, 650, 799, 805] | loss=24.021\n",
            "Step 400: t_list=[812, 616, 732, 692] | loss=24.311\n",
            "Step 450: t_list=[764, 807, 811, 670] | loss=23.953\n",
            "Step 500: t_list=[898, 773, 636, 732] | loss=24.005\n",
            "Step 550: t_list=[657, 702, 772, 599] | loss=24.139\n",
            "Step 600: t_list=[681, 861, 821, 820] | loss=23.969\n",
            "Step 650: t_list=[869, 837, 638, 735] | loss=23.981\n",
            "Step 700: t_list=[732, 628, 676, 720] | loss=24.188\n",
            "Step 750: t_list=[836, 747, 866, 825] | loss=23.811\n",
            "Step 800: t_list=[746, 746, 779, 755] | loss=23.904\n",
            "Step 850: t_list=[789, 829, 604, 895] | loss=24.028\n",
            "Step 900: t_list=[728, 702, 651, 653] | loss=24.194\n",
            "Step 950: t_list=[829, 664, 746, 777] | loss=24.034\n",
            "Step 1000: t_list=[625, 653, 810, 669] | loss=24.115\n",
            "Step 1050: t_list=[798, 894, 795, 873] | loss=24.102\n",
            "Step 1100: t_list=[625, 856, 830, 823] | loss=24.139\n",
            "Step 1150: t_list=[721, 801, 882, 735] | loss=23.990\n",
            "Step 1200: t_list=[793, 703, 655, 732] | loss=24.133\n",
            "Step 1250: t_list=[650, 734, 738, 694] | loss=24.091\n",
            "Step 1300: t_list=[776, 650, 827, 667] | loss=24.045\n",
            "Step 1350: t_list=[643, 607, 897, 736] | loss=24.226\n",
            "Step 1400: t_list=[644, 862, 735, 602] | loss=24.119\n",
            "Step 1450: t_list=[850, 867, 731, 641] | loss=24.089\n",
            "Step 1500: t_list=[797, 621, 661, 632] | loss=24.217\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# Discriminator (DCGAN-style) for CIFAR10 32x32\n",
        "# Output: logits (no sigmoid inside; we use BCEWithLogitsLoss)\n",
        "# ---------------------------------------------------------\n",
        "class DCGANDis(nn.Module):\n",
        "    def __init__(self, ndf=64):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            # (3,32,32) -> (ndf,16,16)\n",
        "            nn.Conv2d(3, ndf, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            # (ndf,16,16) -> (ndf*2,8,8)\n",
        "            nn.Conv2d(ndf, ndf*2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf*2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            # (ndf*2,8,8) -> (ndf*4,4,4)\n",
        "            nn.Conv2d(ndf*2, ndf*4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf*4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            # (ndf*4,4,4) -> (1,1,1)\n",
        "            nn.Conv2d(ndf*4, 1, 4, 1, 0, bias=False)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # returns logits shape (B, 1)\n",
        "        return self.net(x).view(-1, 1)\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# Helper: show a small grid of samples\n",
        "# ---------------------------------------------------------\n",
        "@torch.no_grad()\n",
        "def show_samples(G, title=\"samples\", n=64, z_dim=128):\n",
        "    G.eval()\n",
        "    z = torch.randn(n, z_dim, 1, 1, device=device)\n",
        "    x = G(z).detach().cpu()  # in [-1,1]\n",
        "    x = (x + 1) / 2.0        # to [0,1] for plotting\n",
        "\n",
        "    # Make a square grid\n",
        "    s = int(np.sqrt(n))\n",
        "    x = x[:s*s]\n",
        "    grid = x.view(s, s, 3, 32, 32).permute(0, 3, 1, 4, 2).reshape(s*32, s*32, 3).numpy()\n",
        "\n",
        "    plt.figure(figsize=(5,5))\n",
        "    plt.imshow(grid)\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(title)\n",
        "    plt.show()\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# Standard GAN training loop (DCGAN-ish)\n",
        "# - Same G architecture as yours\n",
        "# - Adds D and trains with BCEWithLogits\n",
        "# ---------------------------------------------------------\n",
        "def train_standard_gan(\n",
        "    G_init,\n",
        "    loader,\n",
        "    steps=2000,\n",
        "    batch_size=64,\n",
        "    z_dim=128,\n",
        "    lr_g=2e-4,\n",
        "    lr_d=2e-4,\n",
        "    betas=(0.5, 0.999),\n",
        "    d_steps=1,\n",
        "    label_smooth=0.9,\n",
        "    log_every=200\n",
        "):\n",
        "    G = copy.deepcopy(G_init).to(device)\n",
        "    D = DCGANDis(ndf=64).to(device)\n",
        "\n",
        "    optG = torch.optim.Adam(G.parameters(), lr=lr_g, betas=betas)\n",
        "    optD = torch.optim.Adam(D.parameters(), lr=lr_d, betas=betas)\n",
        "    bce = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    lossesG, lossesD = [], []\n",
        "\n",
        "    it = iter(loader)\n",
        "    for step in range(1, steps + 1):\n",
        "        try:\n",
        "            real, _ = next(it)\n",
        "        except StopIteration:\n",
        "            it = iter(loader)\n",
        "            real, _ = next(it)\n",
        "\n",
        "        real = real.to(device)\n",
        "\n",
        "        # -------------------------\n",
        "        # (A) Train D\n",
        "        # -------------------------\n",
        "        for _ in range(d_steps):\n",
        "            z = torch.randn(real.size(0), z_dim, 1, 1, device=device)\n",
        "            fake = G(z).detach()\n",
        "\n",
        "            logits_real = D(real)\n",
        "            logits_fake = D(fake)\n",
        "\n",
        "            # real labels ~ 0.9, fake labels ~ 0.0\n",
        "            y_real = torch.full_like(logits_real, label_smooth, device=device)\n",
        "            y_fake = torch.zeros_like(logits_fake, device=device)\n",
        "\n",
        "            lossD = bce(logits_real, y_real) + bce(logits_fake, y_fake)\n",
        "\n",
        "            optD.zero_grad(set_to_none=True)\n",
        "            lossD.backward()\n",
        "            optD.step()\n",
        "\n",
        "        # -------------------------\n",
        "        # (B) Train G (tries to fool D)\n",
        "        # -------------------------\n",
        "        z = torch.randn(real.size(0), z_dim, 1, 1, device=device)\n",
        "        fake = G(z)\n",
        "        logits_fake = D(fake)\n",
        "\n",
        "        # want D(fake)=1\n",
        "        y_gen = torch.ones_like(logits_fake, device=device)\n",
        "        lossG = bce(logits_fake, y_gen)\n",
        "\n",
        "        optG.zero_grad(set_to_none=True)\n",
        "        lossG.backward()\n",
        "        optG.step()\n",
        "\n",
        "        lossesD.append(lossD.item())\n",
        "        lossesG.append(lossG.item())\n",
        "\n",
        "        if step % log_every == 0:\n",
        "            print(f\"[GAN] step {step}/{steps} | lossD={lossD.item():.3f} | lossG={lossG.item():.3f}\")\n",
        "\n",
        "    return G.eval(), D.eval(), lossesG, lossesD\n"
      ],
      "metadata": {
        "id": "IMKpTWMPgpsT"
      },
      "id": "IMKpTWMPgpsT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def eval_ksd_over_t(\n",
        "    G,\n",
        "    ksd,\n",
        "    t_list,\n",
        "    batch_size=64,\n",
        "    z_dim=128,\n",
        "    mc_samples=4,\n",
        "    ridge=1e-3\n",
        "):\n",
        "    G.eval()\n",
        "    vals = []\n",
        "    for t in t_list:\n",
        "        z = torch.randn(batch_size, z_dim, 1, 1, device=device)\n",
        "        fake0 = G(z)\n",
        "        v = ksd.compute_stat(fake0, t=int(t), mc_samples=mc_samples, ridge=ridge).item()\n",
        "        vals.append(v)\n",
        "    return np.array(vals)\n",
        "\n",
        "@torch.no_grad()\n",
        "def real_baseline_over_t(\n",
        "    loader,\n",
        "    ksd,\n",
        "    t_list,\n",
        "    num_batches=3,\n",
        "    mc_samples=4,\n",
        "    ridge=1e-3\n",
        "):\n",
        "    # average KSD(real@t) across a few batches per t\n",
        "    out_mean, out_std = [], []\n",
        "    for t in t_list:\n",
        "        vals = []\n",
        "        it = iter(loader)\n",
        "        for _ in range(num_batches):\n",
        "            xr, _ = next(it)\n",
        "            xr = xr.to(device)\n",
        "            vals.append(ksd.compute_stat(xr, t=int(t), mc_samples=mc_samples, ridge=ridge).item())\n",
        "        out_mean.append(np.mean(vals))\n",
        "        out_std.append(np.std(vals))\n",
        "    return np.array(out_mean), np.array(out_std)\n",
        "\n",
        "def plot_ksd_comparison(t_list, real_mean, real_std, ksd_vals_A, label_A, ksd_vals_B, label_B):\n",
        "    plt.figure(figsize=(7,4))\n",
        "    plt.plot(t_list, ksd_vals_A, marker=\"o\", label=label_A)\n",
        "    plt.plot(t_list, ksd_vals_B, marker=\"o\", label=label_B)\n",
        "    plt.plot(t_list, real_mean, marker=\"o\", label=\"real baseline\")\n",
        "    plt.fill_between(t_list, real_mean-real_std, real_mean+real_std, alpha=0.2)\n",
        "    plt.gca().invert_xaxis()  # optional: show high t on left, low t on right\n",
        "    plt.xlabel(\"t (diffusion step)\")\n",
        "    plt.ylabel(\"KSD@t (diffusion-score)\")\n",
        "    plt.title(\"KSD diagnostic across diffusion levels\")\n",
        "    plt.legend()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "4wVSycKWgsMi"
      },
      "id": "4wVSycKWgsMi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 0) Keep a copy of your KSD-trained generator\n",
        "G_ksd = copy.deepcopy(G).eval()\n",
        "\n",
        "# 1) Train a standard GAN generator from scratch (same architecture)\n",
        "G0 = DCGANGen(z_dim=128).to(device)  # fresh init for fair baseline\n",
        "G_gan, D_gan, lossesG, lossesD = train_standard_gan(\n",
        "    G_init=G0,\n",
        "    loader=loader,\n",
        "    steps=2000,            # start with 2k–5k; increase if stable\n",
        "    batch_size=64,\n",
        "    z_dim=128,\n",
        "    log_every=200\n",
        ")\n",
        "\n",
        "show_samples(G_ksd, title=\"KSD-trained G samples\")\n",
        "show_samples(G_gan, title=\"Standard GAN-trained G samples\")\n",
        "\n",
        "# 2) Evaluate both with KSD@t\n",
        "MC_SAMPLES = 8\n",
        "RIDGE_LAM  = 1e-2\n",
        "\n",
        "# IMPORTANT: don't go too low t initially (that’s where you saw explosions)\n",
        "t_list = [int(x*(T-1)) for x in [0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3]]\n",
        "\n",
        "real_mean, real_std = real_baseline_over_t(\n",
        "    loader, ksd, t_list,\n",
        "    num_batches=3, mc_samples=MC_SAMPLES, ridge=RIDGE_LAM\n",
        ")\n",
        "\n",
        "ksd_ksdG = eval_ksd_over_t(\n",
        "    G_ksd, ksd, t_list,\n",
        "    batch_size=64, z_dim=128, mc_samples=MC_SAMPLES, ridge=RIDGE_LAM\n",
        ")\n",
        "\n",
        "ksd_ganG = eval_ksd_over_t(\n",
        "    G_gan, ksd, t_list,\n",
        "    batch_size=64, z_dim=128, mc_samples=MC_SAMPLES, ridge=RIDGE_LAM\n",
        ")\n",
        "\n",
        "plot_ksd_comparison(t_list, real_mean, real_std, ksd_ksdG, \"G trained by KSD\", ksd_ganG, \"G trained by GAN\")\n"
      ],
      "metadata": {
        "id": "sFDEFnZTgzVR"
      },
      "id": "sFDEFnZTgzVR",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.14"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e51531bd78504d71a828896cb2ecc37f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a78b7b0829d9446f900293b91e19e2df",
              "IPY_MODEL_2a731cb70e0549f5a50d9e4c1734e43f",
              "IPY_MODEL_7143a53510ac49b593e527347fcec615"
            ],
            "layout": "IPY_MODEL_7ed2849475ea48108300e7fd45ed35c7"
          }
        },
        "a78b7b0829d9446f900293b91e19e2df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_753f0ad277f74608881370fcb0c1c2b7",
            "placeholder": "​",
            "style": "IPY_MODEL_2874d5bcd06f4c9a9b3b3e4de2788697",
            "value": "Loading pipeline components...: 100%"
          }
        },
        "2a731cb70e0549f5a50d9e4c1734e43f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ce3aa6d78924c8ca8b3084868d0b6c2",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ef03039327a146559748ab045a4fa4a9",
            "value": 2
          }
        },
        "7143a53510ac49b593e527347fcec615": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f58a213a1bd94d53b97d214cccdd2473",
            "placeholder": "​",
            "style": "IPY_MODEL_b0d5fc358e564bc4a212c7fe7f49efd7",
            "value": " 2/2 [00:00&lt;00:00, 18.23it/s]"
          }
        },
        "7ed2849475ea48108300e7fd45ed35c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "753f0ad277f74608881370fcb0c1c2b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2874d5bcd06f4c9a9b3b3e4de2788697": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3ce3aa6d78924c8ca8b3084868d0b6c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef03039327a146559748ab045a4fa4a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f58a213a1bd94d53b97d214cccdd2473": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0d5fc358e564bc4a212c7fe7f49efd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}